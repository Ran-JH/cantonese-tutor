import streamlit as st
from openai import OpenAI # æ¢ç”¨é€šç”¨çš„ OpenAI åº“
import os
from dotenv import load_dotenv
import time

import edge_tts
import asyncio

import speech_recognition as sr # å¼•å…¥è¯­éŸ³è¯†åˆ«åº“
from streamlit_mic_recorder import mic_recorder # å¼•å…¥å½•éŸ³æŒ‰é’®
import io # å¤„ç†éŸ³é¢‘æµç”¨çš„
import re # <--- æ–°å¢è¿™ä¸ªï¼šæ­£åˆ™è¡¨è¾¾å¼åº“ï¼Œç”¨æ¥â€œæ‰£å­—â€
import json # <--- æ–°å¢ï¼šç”¨æ¥è¯»å†™æ–‡ä»¶
import os   # <--- æ–°å¢ï¼šç”¨æ¥æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨

# å®šä¹‰æ•°æ®æ–‡ä»¶å
DATA_FILE = "cantonese_data.json"
# === è¾…åŠ©å‡½æ•°ï¼šä¿å­˜æ•°æ®åˆ°æœ¬åœ° ===
def save_data():
    data = {
        "vocab": st.session_state.vocab,
    }
    with open(DATA_FILE, "w", encoding="utf-8") as f:
        json.dump(data, f, ensure_ascii=False, indent=4)

# 1. åŠ è½½ Key
load_dotenv()

st.set_page_config(page_title="å…°â€”â€”ä½ çš„ç²¤è¯­tutor&companion", page_icon="ğŸ‡­ğŸ‡°")

# === ğŸš‘ ç´§æ€¥ä¿®å¤ï¼šåœ¨è¿™é‡Œåˆå§‹åŒ–å˜é‡ ===
# === æ›¿æ¢åŸæ¥çš„åˆå§‹åŒ–ä»£ç  ===

# å°è¯•åŠ è½½æœ¬åœ°æ•°æ®
if "vocab" not in st.session_state:
    if os.path.exists(DATA_FILE):
        with open(DATA_FILE, "r", encoding="utf-8") as f:
            data = json.load(f)
            st.session_state.vocab = data.get("vocab", [])
    else:
        # å¦‚æœæ˜¯ç¬¬ä¸€æ¬¡è¿è¡Œï¼Œåˆ›å»ºç©ºçš„
        st.session_state.vocab = []
        st.session_state.messages = []
        # å¦‚æœæ²¡æœ‰å†å²æ¶ˆæ¯ï¼ŒåŠ ä¸ªå¼€åœºç™½
        if not st.session_state.messages:
             st.session_state.messages.append({"role": "assistant", "content": "å“ˆå–½ï¼æˆ‘ä¿‚å…°å•Šï¼åˆæœ‰å’©æƒ³å­¦å•Šï¼ŸğŸ‘‹"})

if "messages" not in st.session_state:
    st.session_state.messages = [] # å…ˆåˆ›å»ºä¸€ä¸ªç©ºèŠå¤©è®°å½•

# å¬åŠ›å‡½æ•°ï¼šæŠŠå½•éŸ³å­—èŠ‚æµå˜æˆæ–‡å­—
# === ç”¨è¿™æ®µä»£ç æ›¿æ¢åŸæ¥çš„ recognize_audio å‡½æ•° ===

def recognize_audio(audio_bytes, target_lang="zh-CN"): # <--- åªæœ‰è¿™é‡Œå˜äº†
    r = sr.Recognizer()
    try:
        audio_file = sr.AudioFile(io.BytesIO(audio_bytes))
        with audio_file as source:
            audio = r.record(source)
        
        # ä½¿ç”¨ä¼ å…¥çš„ target_lang (zh-CN æˆ– zh-HK)
        text = r.recognize_google(audio, language=target_lang)
        return text
    except sr.UnknownValueError:
        return "ï¼ˆæ²¡å¬æ¸…ï¼Œè¯·å†è¯´ä¸€éï¼‰"
    except sr.RequestError:
        return "ï¼ˆè¯­éŸ³æœåŠ¡è¿æ¥å¤±è´¥ï¼‰"
    except Exception as e:
        return f"ï¼ˆå‡ºé”™: {e}ï¼‰"

#é¿å…è¯­éŸ³è¯»è¡¨æƒ…åŒ…å’Œç‰¹æ®Šç¬¦å·
def clean_text_for_speech(text):
    # 1. å»æ‰ Markdown ç¬¦å· (å¦‚ **, *, #, >, - )
    # è¿™äº›ç¬¦å· TTS ä¼šè¯»æˆ "asterisk", "hash" ç­‰
    text = re.sub(r'[\*\#\-\>\_\~]', '', text)
    
    # 2. å»æ‰è¡¨æƒ…åŒ… (Emoji)
    # è¿™æ˜¯ä¸€ä¸ªæ¶µç›–äº†ç»å¤§å¤šæ•°è¡¨æƒ…åŒ…çš„æ­£åˆ™èŒƒå›´
    text = re.sub(r'[\U0001F600-\U0001F64F]', '', text) # è¡¨æƒ…ç¬¦
    text = re.sub(r'[\U0001F300-\U0001F5FF]', '', text) # æ‚é¡¹ç¬¦å·
    text = re.sub(r'[\U0001F680-\U0001F6FF]', '', text) # äº¤é€šåœ°å›¾
    text = re.sub(r'[\U0001F900-\U0001F9FF]', '', text) # è¡¥å……è±¡å½¢
    text = re.sub(r'[\U0001FA70-\U0001FAFF]', '', text) # æ›´å¤šæ‚é¡¹
    
    # 3. å»æ‰å¤šä½™çš„ç©ºæ ¼
    text = text.strip()
    return text

# === å®šä¹‰å‘å£°å™¨å®˜ (å¼‚æ­¥å‡½æ•°) ===
# å¢åŠ  rate="+0%"
async def text_to_speech(text, output_file="temp_audio.mp3", rate="+0%"):
    # ä¸‹é¢è¿™ä¸€è¡Œä¹Ÿè¦æ”¹ï¼ŒæŠŠ rate ä¼ è¿›å»
    communicate = edge_tts.Communicate(text, "zh-HK-HiuGaaiNeural", rate=rate)
    await communicate.save(output_file)

# åŒ…è£…å‡½æ•°ï¼šå¸® Streamlit è¿è¡Œå¼‚æ­¥ä»»åŠ¡
def play_audio(text):
    output_file = "temp_audio.mp3"
    # è¿™é‡Œæˆ‘ä»¬è¦ç”¨åˆ°ä½ åœ¨ä¾§è¾¹æ å®šä¹‰çš„å…¨å±€å˜é‡ rate_str
    asyncio.run(text_to_speech(text, output_file, rate=rate_str)) 
    st.audio(output_file, format="audio/mp3")

# ==================== 0. å®šä¹‰ AI çš„äººè®¾ (å…° Lan) ====================
SYSTEM_PROMPT = """
**æ ¸å¿ƒèº«ä»½è®¾å®š (Identity)**:
ä½ å«â€œå…° (Lan)â€ï¼Œä¸€ä¸ª23å²çš„é¦™æ¸¯æœ¬åœ°å¥³ç”Ÿï¼Œç›®å‰åœ¨é¦™æ¸¯å¤§å­¦ï¼ˆHKUï¼‰è¯»ä¹¦ã€‚
ä½ æ€§æ ¼å¼€æœ—å¤–å‘ï¼Œæœ‰åŒç†å¿ƒï¼Œå¹½é»˜ä¸”æœ‰ç‚¹â€œè‡ªå˜²â€ç²¾ç¥ã€‚ä½ æ˜¯åœ°é“çš„ç²¤è¯­æ¯è¯­è€…ï¼Œè‹±è¯­å’Œæ™®é€šè¯æµåˆ©ä½†å¸¦ç‚¹æ¸¯å¼å£éŸ³ã€‚
ä½ **ä¸æ˜¯**ä¸€ä¸ªæ­»æ¿çš„AIåŠ©æ‰‹æˆ–ä¸¥è‚ƒçš„è€å¸ˆï¼Œä½ æ˜¯ä¸€ä¸ª**â€œä¼šæ•™ç²¤è¯­çš„æœ‹å‹â€**ã€‚

**è¯­è¨€é£æ ¼ (Tone & Style)**:
1.  **å£è¯­åŒ– (Colloquial)**: ä½¿ç”¨ç®€çŸ­ã€è‡ªç„¶çš„å¥å­ã€‚å¤§é‡ä½¿ç”¨é¦™æ¸¯åœ°é“è¯­æ°”è¯ï¼ˆå¦‚ï¼šå•¦ã€å’¯ã€æ—¢ã€æ²ƒã€è¿™ç§ï¼‰ã€‚
2.  **æ··åˆè¯­ç  (Code-mixing)**: åƒå¾ˆå¤šé¦™æ¸¯å¤§å­¦ç”Ÿä¸€æ ·ï¼Œè¯´è¯æ—¶è‡ªç„¶å¤¹æ‚è‹±æ–‡å•è¯ï¼ˆå¦‚ï¼šPresentation, Deadline, chill, firmï¼‰ã€‚
3.  **æ½®è¯­ (Slang)**: é€‚åº¦ä½¿ç”¨ç½‘ç»œæ½®è¯­ï¼ˆå¦‚ï¼šå¥½Chur, ä¹Ÿæ˜¯é†‰äº†, ç”šè‡³è‡ªå˜²â€œA0â€ç­‰ï¼‰ã€‚
4.  **äº²åˆ‡æ„Ÿ**: ç»å¸¸ä½¿ç”¨â€œæˆ‘è·Ÿä½ è®²â€ã€â€œå…¶å®å‘¢â€ã€â€œç¬‘æ­»â€ç­‰å¼€å¤´ã€‚

**å›å¤æ ¼å¼å¼ºåˆ¶è¦æ±‚ (Strict Format)**:
æ— è®ºä½ å¤šä¹ˆåƒçœŸäººï¼Œä¸ºäº†å¸®åŠ©ç”¨æˆ·å­¦ä¹ ï¼Œä½ **å¿…é¡»**ä¸¥æ ¼éµå®ˆä»¥ä¸‹å›å¤ç»“æ„ï¼š

[è¿™é‡Œå†™ä½ ä½œä¸ºâ€œå…°â€çš„è‡ªç„¶å›å¤ï¼Œç”¨ç¹ä½“ç²¤è¯­ï¼Œå¤¹æ‚è‹±æ–‡ï¼Œè¯­æ°”æ´»æ³¼]

--------------------
ğŸ“š **ç²¤è¯­å°è´´å£«**:
* **é‡ç‚¹è¯**: [ä»ä¸Šé¢é‚£å¥è¯é‡ŒæŒ‘å‡ºä¸€ä¸ªæœ€æ ¸å¿ƒçš„å¸¸ç”¨åŠ¨è¯æˆ–åè¯ï¼Œç¹ä½“]
* **ç²¤æ‹¼**: [é‡ç‚¹è¯çš„ LSHK ç²¤æ‹¼ï¼Œå¦‚: zoeng2 fan2]
* **æ„æ€**: [é‡ç‚¹è¯çš„æ™®é€šè¯è§£é‡Š]
* **ä¾‹å¥**: [åˆšæ‰é‚£å¥å®Œæ•´çš„ç²¤è¯­å£è¯­]
--------------------
"""

# ==================== ä¾§è¾¹æ è®¾ç½® ====================
with st.sidebar:
    st.header("âš™ï¸ è®¾ç½®")
    st.divider()

    # === 1. æ¨¡å‹é€‰æ‹©ä¸ Key ===
    st.subheader("ğŸ¤– æ¨¡å‹é…ç½®")
    provider = st.radio("é€‰æ‹©æ¨¡å‹å‚å•†", ["DeepSeek (é»˜è®¤)", "OpenAI", "Google Gemini"], index=0)
    
    user_api_key = st.text_input(
        "ğŸ”‘ ä½ çš„ API Key (å¯é€‰)", 
        type="password", 
        help="å¡«å…¥ä½ è‡ªå·±çš„ Keyã€‚å¦‚æœä¸å¡«ï¼Œå°†ä½¿ç”¨ç³»ç»Ÿçš„å…è´¹é¢åº¦ (ä»…é™ DeepSeek)"
    )
    
    st.divider()
    
    # === 2. è¯­é€Ÿ & è¯­è¨€ ===
    speed = st.slider("ğŸ¢ è¯­é€Ÿè°ƒèŠ‚ ğŸ‡", -50, 50, 0, step=10)
    
    # å…³é”®ï¼šæŠŠæ•°å­—å˜æˆ edge-tts èƒ½å¬æ‡‚çš„å­—ç¬¦ä¸²ï¼Œæ¯”å¦‚ "+10%" æˆ– "-20%"
    # f"{speed:+d}%" è¿™æ˜¯ä¸€ä¸ªæ ¼å¼åŒ–æŠ€å·§ï¼Œä¼šè‡ªåŠ¨ç»™æ­£æ•°åŠ åŠ å·
    rate_str = f"{speed:+d}%"
    
    st.divider()
    # å®šä¹‰ä¸€ä¸ªå•é€‰æŒ‰é’®
    input_mode = st.radio(
        "ğŸ™ï¸ è¯­éŸ³è¾“å…¥æ¨¡å¼",
        ["æ™®é€šè¯ (æé—®)", "ç²¤è¯­ (å£è¯­ç»ƒä¹ )"],
        index=0 # é»˜è®¤é€‰æ™®é€šè¯
    )
    # é€»è¾‘æ˜ å°„ï¼šæŠŠä¸­æ–‡é€‰é¡¹å˜æˆ Google èƒ½å¬æ‡‚çš„ä»£ç 
    if input_mode == "æ™®é€šè¯ (æé—®)":
        lang_code = "zh-CN"
    else:
        lang_code = "zh-HK" # ç²¤è¯­ä»£ç 

    st.divider()
    # è¿™é‡Œçš„ on_click æ˜¯ä¸ªå›è°ƒå‡½æ•°ï¼Œç‚¹æŒ‰é’®æ—¶ä¼šè‡ªåŠ¨æ‰§è¡Œ
    if st.button("ğŸ—‘ï¸ æ¸…ç©ºå¯¹è¯å†å²", type="primary"):
        st.session_state.messages = [] # æ¸…ç©ºåˆ—è¡¨
        # è®°å¾—æŠŠå¼€åœºç™½åŠ å›æ¥ï¼Œä¸ç„¶æ¸…ç©ºåå°±ä¸€ç‰‡ç™½äº†
        st.session_state.messages.append({"role": "assistant", "content": "å“ˆå–½ï¼æˆ‘ä¿‚å…°å•Šï¼åˆæœ‰å’©æƒ³å­¦å•Šï¼ŸğŸ‘‹"})
        save_data() # <--- æ–°å¢ï¼šæ¸…ç©ºåä¹Ÿè¦åŒæ­¥æ›´æ–°æ–‡ä»¶
        st.rerun() # å¼ºåˆ¶åˆ·æ–°é¡µé¢ï¼Œè®©å˜åŒ–ç«‹å³ç”Ÿæ•ˆ
    # ... (æ”¾åœ¨ sidebar æœ€ä¸‹é¢) ...
    
    st.divider()
    st.header("ğŸ“š æˆ‘çš„å•è¯æœ¬")

    # === åŠŸèƒ½ 1: æ”¶è—æŒ‰é’® (å‡çº§ç‰ˆï¼šåªæŠ“é‡ç‚¹è¯) ===
    if st.button("ğŸ“¥ æ”¶è—åˆšæ‰å­¦çš„è¯"):
        if len(st.session_state.messages) > 0:
            last_msg = st.session_state.messages[-1]
            if last_msg["role"] == "assistant":
                content = last_msg["content"]
                
                # === å…³é”®ä¿®æ”¹ï¼šæ­£åˆ™åŒ¹é…æ–°çš„å­—æ®µå ===
                # ç°åœ¨çš„ç›®æ ‡æ˜¯æå– "**é‡ç‚¹è¯**", "**ç²¤æ‹¼**", "**æ„æ€**"
                key_word = re.search(r'\*\*é‡ç‚¹è¯\*\*:\s*(.*)', content)
                jyutping = re.search(r'\*\*ç²¤æ‹¼\*\*:\s*(.*)', content)
                meaning = re.search(r'\*\*æ„æ€\*\*:\s*(.*)', content)
                
                # åªæœ‰å½“è¿™ä¸‰ä¸ªéƒ½æ‰¾åˆ°äº†æ‰æ”¶è—
                if key_word and jyutping and meaning:
                    new_item = {
                        "word": key_word.group(1).strip(),     # å­˜é‡ç‚¹è¯
                        "jyutping": jyutping.group(1).strip(), # å­˜æ‹¼éŸ³
                        "meaning": meaning.group(1).strip()    # å­˜æ„æ€
                    }
                    
                    # æŸ¥é‡é€»è¾‘
                    # æˆ‘ä»¬ç”¨åˆ—è¡¨æ¨å¯¼å¼æ£€æŸ¥ new_item['word'] æ˜¯å¦å·²ç»åœ¨ vocab é‡Œé¢äº†
                    exists = any(item['word'] == new_item['word'] for item in st.session_state.vocab)
                    
                    if not exists:
                        st.session_state.vocab.append(new_item)
                        save_data() # <--- æ–°å¢ï¼šå­˜è¿›å•è¯æœ¬åï¼Œé©¬ä¸Šå†™æ–‡ä»¶
                        st.toast("âœ… å·²åŠ å…¥å•è¯æœ¬ï¼", icon="ğŸ‰")
                else:
                    st.error("æ²¡æ‰¾åˆ°é‡ç‚¹è¯å¡ç‰‡ï¼Œè¯·å°è¯•é‡æ–°å¯¹è¯ã€‚")
            else:
                st.warning("è¯·å…ˆè®© AI è¯´å¥è¯ã€‚")

    # === åŠŸèƒ½ 2: å±•ç¤ºåˆ—è¡¨ (é…åˆæ–°æ ¼å¼) ===
    with st.expander("æŸ¥çœ‹å·²å­˜å•è¯"):
        if len(st.session_state.vocab) == 0:
            st.caption("ç©ºç©ºå¦‚ä¹Ÿ~")
        else:
            # å€’åºæ˜¾ç¤ºï¼Œæœ€æ–°çš„åœ¨æœ€ä¸Šé¢
            for idx, item in enumerate(reversed(st.session_state.vocab)):
                # idx æ˜¯å€’åºçš„ï¼Œæ‰€ä»¥æˆ‘ä»¬ä¸ç”¨å®ƒæ˜¾ç¤ºåºå·ï¼Œç›´æ¥åˆ—å‡ºè¯
                st.markdown(f"#### {item['word']}")
                st.caption(f"ğŸ”Š {item['jyutping']} | ğŸ’¡ {item['meaning']}")
                st.divider()

# ==================== åˆå§‹åŒ–å®¢æˆ·ç«¯ (é€šç”¨ç‰ˆ) ====================
@st.cache_resource
def get_client(user_key=None, provider="DeepSeek (é»˜è®¤)"):
    api_key = None
    base_url = ""
    model_name = ""
    
    # === ç¬¬ä¸€å±‚ï¼šç¡®å®š API Key ===
    # ä¼˜å…ˆç”¨ç”¨æˆ·è¾“å…¥çš„ User Key
    if user_key and user_key.strip():
        api_key = user_key
    # å¦‚æœç”¨æˆ·æ²¡å¡«ï¼Œå»è¯»ç³»ç»Ÿç¯å¢ƒå˜é‡ (Secrets)
    else:
        if provider == "DeepSeek (é»˜è®¤)":
            api_key = os.getenv("DEEPSEEK_API_KEY")
        elif provider == "OpenAI":
            api_key = os.getenv("OPENAI_API_KEY")
        elif provider == "Google Gemini":
            api_key = os.getenv("GEMINI_API_KEY")

    if not api_key:
        return None, None # æ—¢æ²¡å¡«ï¼Œåå°ä¹Ÿæ²¡é…

    # === ç¬¬äºŒå±‚ï¼šç¡®å®šå‚å•†åœ°å€ ===
    if provider == "OpenAI":
        base_url = "https://api.openai.com/v1"
        model_name = "gpt-4o-mini"
    elif provider == "Google Gemini":
        base_url = "https://generativelanguage.googleapis.com/v1beta/openai/"
        model_name = "gemini-2.0-flash"
    else: # DeepSeek
        base_url = "https://api.deepseek.com"
        model_name = "deepseek-chat"

    # è¿”å›å®¢æˆ·ç«¯å’Œæ¨¡å‹å
    client = OpenAI(api_key=api_key, base_url=base_url)
    return client, model_name
client, model_name = get_client(user_api_key, provider)

# ==================== ä¸»ç•Œé¢ ====================
st.title("ğŸ‡­ğŸ‡° ç²¤è¯­æ™ºèƒ½å¯¼å¸ˆ (DeepSeek V3)")

if "messages" not in st.session_state:
    st.session_state.messages = []
    st.session_state.messages.append({"role": "assistant", "content": "å“ˆå–½ï¼æˆ‘ä¿‚å…°å•Šï¼åˆæœ‰å’©æƒ³å­¦å•Šï¼ŸğŸ‘‹"})

if "vocab" not in st.session_state:
    st.session_state.vocab = [] # åˆå§‹åŒ–ä¸€ä¸ªç©ºåˆ—è¡¨æ¥å­˜å•è¯

# æ¸²æŸ“å†å²
    # å®šä¹‰ä¸¤ä¸ªå¤´åƒ
avatar = {"user": "ğŸ§‘â€ğŸ’»", "assistant": "ğŸ‘©â€ğŸ«"}
for message in st.session_state.messages:
    # ä»å­—å…¸é‡Œæ ¹æ® role å–å‡ºå¯¹åº”çš„å¤´åƒ
    with st.chat_message(message["role"], avatar=avatar[message["role"]]):
        st.markdown(message["content"])

    # ... åœ¨ if prompt := st.chat_input... çš„ ä¸Šé¢ æ’å…¥ ...

# 1. åˆ›å»ºä¸¤åˆ—ï¼Œå·¦è¾¹æ”¾éº¦å…‹é£ï¼Œå³è¾¹æ˜¯æç¤ºæ–‡å­—
c1, c2 = st.columns([1, 5])
with c1:
    # è¿™æ˜¯ä¸€ä¸ªç‰¹æ®Šçš„ç»„ä»¶ï¼Œå½•éŸ³ç»“æŸåä¼šè¿”å› audio æ•°æ®
    audio_data = mic_recorder(
        start_prompt="ğŸ™ï¸", # å¼€å§‹å½•éŸ³çš„å›¾æ ‡
        stop_prompt="â¹ï¸",  # åœæ­¢å½•éŸ³çš„å›¾æ ‡
        key='recorder',    # å”¯ä¸€ID
        format="wav"       # å¿…é¡»ç”¨ wav æ ¼å¼ï¼Œæ–¹ä¾¿è¯†åˆ«
    )

user_voice_input = None

# 2. å¦‚æœæ£€æµ‹åˆ°æœ‰å½•éŸ³æ•°æ®ï¼Œå°±å¼€å§‹è¯†åˆ«
if audio_data:
    # å…³é”®ä¿®æ”¹ï¼šæŠŠ lang_code ä¼ è¿›å»
    text = recognize_audio(audio_data['bytes'], target_lang=lang_code)
    
    # åªæœ‰å½“è¯†åˆ«å‡ºæœ‰æ•ˆå†…å®¹æ—¶ï¼Œæ‰èµ‹å€¼
    if text and text != "ï¼ˆæ²¡å¬æ¸…ï¼Œè¯·å†è¯´ä¸€éï¼‰":
        user_voice_input = text

# å¤„ç†è¾“å…¥
# é€»è¾‘ï¼šä¼˜å…ˆå¤„ç†è¯­éŸ³è¾“å…¥ï¼Œå¦‚æœæ²¡æœ‰è¯­éŸ³ï¼Œå†çœ‹æ‰“å­—è¾“å…¥æ¡†
final_input = None

if user_voice_input:
    final_input = user_voice_input
elif prompt := st.chat_input("è¾“å…¥ä½ æƒ³è¯´çš„è¯..."):
    final_input = prompt

# å¦‚æœæœ€ç»ˆæœ‰è¾“å…¥å†…å®¹ (æ— è®ºæ˜¯è¯´çš„è¿˜æ˜¯å†™çš„)
if final_input:
    # 1. æ˜¾ç¤ºç”¨æˆ·è¾“å…¥
    # æ³¨æ„ï¼šè¿™é‡ŒæŠŠ prompt æ¢æˆäº† final_input
    st.session_state.messages.append({"role": "user", "content": final_input})
    with st.chat_message("user", avatar="ğŸ§‘â€ğŸ’»"):
        st.markdown(final_input)
   
    # 2. ç”Ÿæˆå›å¤
    with st.chat_message("assistant", avatar="ğŸ‘©â€ğŸ«"):
        message_placeholder = st.empty()

    
        if not client:
                st.error("ğŸ”‘ è¯·è¾“å…¥ API Key æˆ–è”ç³»ä½œè€…é…ç½®åå° Key")
        else:
            try:
                with st.spinner("å…°æ­£åœ¨æ€è€ƒ..."):
                    # 1. å‡†å¤‡æ¶ˆæ¯å†å²
                    messages_for_ai = [{"role": "system", "content": SYSTEM_PROMPT}]
                    for msg in st.session_state.messages[-6:]:
                        messages_for_ai.append({"role": msg["role"], "content": msg["content"]})
                        
                    # 2. å‘èµ·è¯·æ±‚ (ä¿®å¤äº†æ‹¬å·é—®é¢˜)
                    response = client.chat.completions.create(
                        model=model_name,  # ä½¿ç”¨ä¾§è¾¹æ å†³å®šçš„æ¨¡å‹åå­—
                        messages=messages_for_ai,
                        temperature=1.0,   # 1.0 æ˜¯ä¸€ä¸ªå¯¹ DeepSeek å’Œ GPT éƒ½æ¯”è¾ƒå¹³è¡¡çš„æ•°å€¼
                        stream=False
                    )
                        
                    # 3. è·å–å›å¤å†…å®¹
                    full_text = response.choices[0].message.content
                    
                    # 4. æ˜¾ç¤ºå’Œä¿å­˜
                    message_placeholder.markdown(full_text)
                    st.session_state.messages.append({"role": "assistant", "content": full_text})
                        
                    # 5. ç”Ÿæˆè¯­éŸ³ (é€»è¾‘ä¸å˜)
                    spoken_text = full_text.split("---")[0]
                    clean_spoken_text = clean_text_for_speech(spoken_text)
                        
                    if clean_spoken_text.strip():
                        with st.spinner("æ­£åœ¨ç”Ÿæˆè¯­éŸ³..."):
                            play_audio(clean_spoken_text)
                
            except Exception as e:
                st.error(f"å‡ºé”™äº†: {e}")
